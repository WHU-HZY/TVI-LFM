{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.word as naw \n",
    "from nlpaug.util import Action\n",
    "# 固定增强种子\n",
    "import random\n",
    "random.seed(0)\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import nltk\n",
    "nltk.data.path = ['/data1/hzy_data/nltk_data/packages']\n",
    "class nlp_Compose:\n",
    "    def __init__(self, aug_list):\n",
    "        self.aug_list = aug_list\n",
    "\n",
    "    def __call__(self, sentence):\n",
    "        for a in self.aug_list:\n",
    "            sentence = a.augment(sentence)[0]\n",
    "        return sentence\n",
    "# aug = naw.ContextualWordEmbsAug(\n",
    "#     model_path='/home/hzy/.cache/huggingface/hub/models--google-bert--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594', action=\"insert\")\n",
    "# aug_1 = naw.WordEmbsAug(model_type='word2vec', model_path='.',action=\"insert\", aug_p=0.3, stopwords=['a', 'an', 'the'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.24.4\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_1 = naw.SynonymAug(aug_p=0.3, stopwords=['a', 'an', 'the'])\n",
    "aug_2 = naw.RandomWordAug(action=Action.SWAP, aug_p=0.3, stopwords=['a', 'an', 'the'])\n",
    "\n",
    "\n",
    "transform = nlp_Compose([aug_1, aug_2])\n",
    "text = 'a man with a short black hair wearing a half sleeves black and white round neck t shirt and black jeans with a paired of black casual shoes, he is carrying a black backpack.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a man with a black hair short wearing a half blackened sleeves white and round neck opening thyroxin shirt and jeans ignominious a with paired of shoes black casual, is helium a carrying fateful knapsack.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt was a dark and stormy night. I was alone at home when I saw a lion\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms face followed by a scary thunderous roar at the windows.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Back translation\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m aug \u001b[38;5;241m=\u001b[39m \u001b[43mnaw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBackTranslationAug\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m augmented_text \u001b[38;5;241m=\u001b[39m aug\u001b[38;5;241m.\u001b[39maugment(text)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(augmented_text)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.10/site-packages/nlpaug/augmenter/word/back_translation.py:61\u001b[0m, in \u001b[0;36mBackTranslationAug.__init__\u001b[0;34m(self, from_model_name, to_model_name, name, device, batch_size, max_length, force_reload, verbose)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, from_model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfacebook/wmt19-en-de\u001b[39m\u001b[38;5;124m'\u001b[39m, to_model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfacebook/wmt19-de-en\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     56\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBackTranslationAug\u001b[39m\u001b[38;5;124m'\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m, force_reload\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     58\u001b[0m         action\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubstitute\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39mname, aug_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, aug_min\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, aug_max\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, tokenizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     59\u001b[0m         device\u001b[38;5;241m=\u001b[39mdevice, verbose\u001b[38;5;241m=\u001b[39mverbose, include_detail\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfrom_model_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_model_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_model_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mto_model_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdevice\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.10/site-packages/nlpaug/augmenter/word/back_translation.py:76\u001b[0m, in \u001b[0;36mBackTranslationAug.get_model\u001b[0;34m(cls, from_model_name, to_model_name, device, force_reload, batch_size, max_length)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_model\u001b[39m(\u001b[38;5;28mcls\u001b[39m, from_model_name, to_model_name, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, force_reload\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     75\u001b[0m               batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minit_back_translation_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfrom_model_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_model_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_reload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.10/site-packages/nlpaug/augmenter/word/back_translation.py:25\u001b[0m, in \u001b[0;36minit_back_translation_model\u001b[0;34m(from_model_name, to_model_name, device, force_reload, batch_size, max_length)\u001b[0m\n\u001b[1;32m     21\u001b[0m     BACK_TRANSLATION_MODELS[model_name]\u001b[38;5;241m.\u001b[39mmax_length \u001b[38;5;241m=\u001b[39m max_length\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m BACK_TRANSLATION_MODELS[model_name]\n\u001b[0;32m---> 25\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mnml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMtTransformers\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_model_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_model_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_model_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mto_model_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m BACK_TRANSLATION_MODELS[model_name] \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.10/site-packages/nlpaug/model/lang_models/machine_translation_transformers.py:23\u001b[0m, in \u001b[0;36mMtTransformers.__init__\u001b[0;34m(self, src_model_name, tgt_model_name, device, silence, batch_size, max_length)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msrc_model_name \u001b[38;5;241m=\u001b[39m src_model_name\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtgt_model_name \u001b[38;5;241m=\u001b[39m tgt_model_name\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msrc_model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForSeq2SeqLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msrc_model_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msrc_model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msrc_model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:441\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs_copy\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    439\u001b[0m         _ \u001b[38;5;241m=\u001b[39m kwargs_copy\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 441\u001b[0m     config, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mAutoConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_unused_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs_copy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mauto_map:\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m trust_remote_code:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:896\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    894\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname_or_path\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pretrained_model_name_or_path\n\u001b[1;32m    895\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 896\u001b[0m config_dict, unused_kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mPretrainedConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m trust_remote_code:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.10/site-packages/transformers/configuration_utils.py:573\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    571\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    572\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 573\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[1;32m    575\u001b[0m     original_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.10/site-packages/transformers/configuration_utils.py:628\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    624\u001b[0m configuration_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_configuration_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, CONFIG_NAME)\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    642\u001b[0m     commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[1;32m    644\u001b[0m     \u001b[38;5;66;03m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001b[39;00m\n\u001b[1;32m    645\u001b[0m     \u001b[38;5;66;03m# the original exception.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.10/site-packages/transformers/utils/hub.py:409\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    406\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 409\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError:\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    425\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    426\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    427\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpass a token having permission to this repo with `use_auth_token` or log in with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    428\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`huggingface-cli login` and pass `use_auth_token=True`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    429\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1232\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, endpoint, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1231\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1232\u001b[0m         metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1233\u001b[0m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1234\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1235\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1236\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1237\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1238\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n\u001b[1;32m   1239\u001b[0m         \u001b[38;5;66;03m# Cache the non-existence of the file and raise\u001b[39;00m\n\u001b[1;32m   1240\u001b[0m         commit_hash \u001b[38;5;241m=\u001b[39m http_error\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(HUGGINGFACE_HEADER_X_REPO_COMMIT)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1599\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout)\u001b[0m\n\u001b[1;32m   1596\u001b[0m headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccept-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midentity\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# prevent any compression => we want to know the real size of the file\u001b[39;00m\n\u001b[1;32m   1598\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1599\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1600\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1601\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1602\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1603\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1604\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1605\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1606\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1607\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1608\u001b[0m hf_raise_for_status(r)\n\u001b[1;32m   1610\u001b[0m \u001b[38;5;66;03m# Return\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:417\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, max_retries, base_wait_time, max_wait_time, timeout, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;66;03m# 2. Force relative redirection\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 417\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_wait_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_wait_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_wait_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_wait_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m300\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m399\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:452\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, max_retries, base_wait_time, max_wait_time, timeout, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# 3. Exponential backoff\u001b[39;00m\n\u001b[0;32m--> 452\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhttp_backoff\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_wait_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_wait_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_wait_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_wait_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry_on_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mTimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mProxyError\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry_on_status_codes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:258\u001b[0m, in \u001b[0;36mhttp_backoff\u001b[0;34m(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mseek(io_obj_initial_pos)\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[0;32m--> 258\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m retry_on_status_codes:\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.10/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.10/site-packages/requests/sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    700\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    704\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:63\u001b[0m, in \u001b[0;36mUniqueRequestIdAdapter.send\u001b[0;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Catch any RequestException to append request id to the error message for debugging.\"\"\"\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     65\u001b[0m     request_id \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(X_AMZN_TRACE_ID)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.10/site-packages/requests/adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 489\u001b[0m         resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m            \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m            \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproxy_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.10/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.10/site-packages/urllib3/connectionpool.py:386\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 386\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mconn\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.10/site-packages/urllib3/connectionpool.py:1042\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[0;32m-> 1042\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n\u001b[1;32m   1045\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1046\u001b[0m         (\n\u001b[1;32m   1047\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnverified HTTPS request is being made to host \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1052\u001b[0m         InsecureRequestWarning,\n\u001b[1;32m   1053\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.10/site-packages/urllib3/connection.py:358\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;66;03m# Add certificate verification\u001b[39;00m\n\u001b[0;32m--> 358\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    359\u001b[0m     hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[1;32m    360\u001b[0m     tls_in_tls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.10/site-packages/urllib3/connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    171\u001b[0m     extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msocket_options\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket_options\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConnectTimeoutError(\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    181\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m timed out. (connect timeout=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    182\u001b[0m         \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout),\n\u001b[1;32m    183\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.10/site-packages/urllib3/util/connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[1;32m     84\u001b[0m         sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 85\u001b[0m     \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sock\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39merror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import nlpaug.augmenter.word as naw\n",
    "\n",
    "text = \"It was a dark and stormy night. I was alone at home when I saw a lion's face followed by a scary thunderous roar at the windows.\"\n",
    "\n",
    "# Back translation\n",
    "aug = naw.BackTranslationAug()\n",
    "augmented_text = aug.augment(text)\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huzhangyi/anaconda3/envs/torch_env/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/huzhangyi/anaconda3/envs/torch_env/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "# resnet = torchvision.models.resnet50(pretrained=True)\n",
    "\n",
    "pretrain_path = \"/data1/hzy_log/pretrain_cache/clip/RN50.pt\"\n",
    "resnet = torchvision.models.resnet50(pretrained=False)\n",
    "model = torch.jit.load(pretrain_path).state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['positional_embedding', 'text_projection', 'logit_scale', 'input_resolution', 'context_length', 'vocab_size', 'visual.conv1.weight', 'visual.bn1.weight', 'visual.bn1.bias', 'visual.bn1.running_mean', 'visual.bn1.running_var', 'visual.bn1.num_batches_tracked', 'visual.conv2.weight', 'visual.bn2.weight', 'visual.bn2.bias', 'visual.bn2.running_mean', 'visual.bn2.running_var', 'visual.bn2.num_batches_tracked', 'visual.conv3.weight', 'visual.bn3.weight', 'visual.bn3.bias', 'visual.bn3.running_mean', 'visual.bn3.running_var', 'visual.bn3.num_batches_tracked', 'visual.layer1.0.conv1.weight', 'visual.layer1.0.bn1.weight', 'visual.layer1.0.bn1.bias', 'visual.layer1.0.bn1.running_mean', 'visual.layer1.0.bn1.running_var', 'visual.layer1.0.bn1.num_batches_tracked', 'visual.layer1.0.conv2.weight', 'visual.layer1.0.bn2.weight', 'visual.layer1.0.bn2.bias', 'visual.layer1.0.bn2.running_mean', 'visual.layer1.0.bn2.running_var', 'visual.layer1.0.bn2.num_batches_tracked', 'visual.layer1.0.conv3.weight', 'visual.layer1.0.bn3.weight', 'visual.layer1.0.bn3.bias', 'visual.layer1.0.bn3.running_mean', 'visual.layer1.0.bn3.running_var', 'visual.layer1.0.bn3.num_batches_tracked', 'visual.layer1.0.downsample.0.weight', 'visual.layer1.0.downsample.1.weight', 'visual.layer1.0.downsample.1.bias', 'visual.layer1.0.downsample.1.running_mean', 'visual.layer1.0.downsample.1.running_var', 'visual.layer1.0.downsample.1.num_batches_tracked', 'visual.layer1.1.conv1.weight', 'visual.layer1.1.bn1.weight', 'visual.layer1.1.bn1.bias', 'visual.layer1.1.bn1.running_mean', 'visual.layer1.1.bn1.running_var', 'visual.layer1.1.bn1.num_batches_tracked', 'visual.layer1.1.conv2.weight', 'visual.layer1.1.bn2.weight', 'visual.layer1.1.bn2.bias', 'visual.layer1.1.bn2.running_mean', 'visual.layer1.1.bn2.running_var', 'visual.layer1.1.bn2.num_batches_tracked', 'visual.layer1.1.conv3.weight', 'visual.layer1.1.bn3.weight', 'visual.layer1.1.bn3.bias', 'visual.layer1.1.bn3.running_mean', 'visual.layer1.1.bn3.running_var', 'visual.layer1.1.bn3.num_batches_tracked', 'visual.layer1.2.conv1.weight', 'visual.layer1.2.bn1.weight', 'visual.layer1.2.bn1.bias', 'visual.layer1.2.bn1.running_mean', 'visual.layer1.2.bn1.running_var', 'visual.layer1.2.bn1.num_batches_tracked', 'visual.layer1.2.conv2.weight', 'visual.layer1.2.bn2.weight', 'visual.layer1.2.bn2.bias', 'visual.layer1.2.bn2.running_mean', 'visual.layer1.2.bn2.running_var', 'visual.layer1.2.bn2.num_batches_tracked', 'visual.layer1.2.conv3.weight', 'visual.layer1.2.bn3.weight', 'visual.layer1.2.bn3.bias', 'visual.layer1.2.bn3.running_mean', 'visual.layer1.2.bn3.running_var', 'visual.layer1.2.bn3.num_batches_tracked', 'visual.layer2.0.conv1.weight', 'visual.layer2.0.bn1.weight', 'visual.layer2.0.bn1.bias', 'visual.layer2.0.bn1.running_mean', 'visual.layer2.0.bn1.running_var', 'visual.layer2.0.bn1.num_batches_tracked', 'visual.layer2.0.conv2.weight', 'visual.layer2.0.bn2.weight', 'visual.layer2.0.bn2.bias', 'visual.layer2.0.bn2.running_mean', 'visual.layer2.0.bn2.running_var', 'visual.layer2.0.bn2.num_batches_tracked', 'visual.layer2.0.conv3.weight', 'visual.layer2.0.bn3.weight', 'visual.layer2.0.bn3.bias', 'visual.layer2.0.bn3.running_mean', 'visual.layer2.0.bn3.running_var', 'visual.layer2.0.bn3.num_batches_tracked', 'visual.layer2.0.downsample.0.weight', 'visual.layer2.0.downsample.1.weight', 'visual.layer2.0.downsample.1.bias', 'visual.layer2.0.downsample.1.running_mean', 'visual.layer2.0.downsample.1.running_var', 'visual.layer2.0.downsample.1.num_batches_tracked', 'visual.layer2.1.conv1.weight', 'visual.layer2.1.bn1.weight', 'visual.layer2.1.bn1.bias', 'visual.layer2.1.bn1.running_mean', 'visual.layer2.1.bn1.running_var', 'visual.layer2.1.bn1.num_batches_tracked', 'visual.layer2.1.conv2.weight', 'visual.layer2.1.bn2.weight', 'visual.layer2.1.bn2.bias', 'visual.layer2.1.bn2.running_mean', 'visual.layer2.1.bn2.running_var', 'visual.layer2.1.bn2.num_batches_tracked', 'visual.layer2.1.conv3.weight', 'visual.layer2.1.bn3.weight', 'visual.layer2.1.bn3.bias', 'visual.layer2.1.bn3.running_mean', 'visual.layer2.1.bn3.running_var', 'visual.layer2.1.bn3.num_batches_tracked', 'visual.layer2.2.conv1.weight', 'visual.layer2.2.bn1.weight', 'visual.layer2.2.bn1.bias', 'visual.layer2.2.bn1.running_mean', 'visual.layer2.2.bn1.running_var', 'visual.layer2.2.bn1.num_batches_tracked', 'visual.layer2.2.conv2.weight', 'visual.layer2.2.bn2.weight', 'visual.layer2.2.bn2.bias', 'visual.layer2.2.bn2.running_mean', 'visual.layer2.2.bn2.running_var', 'visual.layer2.2.bn2.num_batches_tracked', 'visual.layer2.2.conv3.weight', 'visual.layer2.2.bn3.weight', 'visual.layer2.2.bn3.bias', 'visual.layer2.2.bn3.running_mean', 'visual.layer2.2.bn3.running_var', 'visual.layer2.2.bn3.num_batches_tracked', 'visual.layer2.3.conv1.weight', 'visual.layer2.3.bn1.weight', 'visual.layer2.3.bn1.bias', 'visual.layer2.3.bn1.running_mean', 'visual.layer2.3.bn1.running_var', 'visual.layer2.3.bn1.num_batches_tracked', 'visual.layer2.3.conv2.weight', 'visual.layer2.3.bn2.weight', 'visual.layer2.3.bn2.bias', 'visual.layer2.3.bn2.running_mean', 'visual.layer2.3.bn2.running_var', 'visual.layer2.3.bn2.num_batches_tracked', 'visual.layer2.3.conv3.weight', 'visual.layer2.3.bn3.weight', 'visual.layer2.3.bn3.bias', 'visual.layer2.3.bn3.running_mean', 'visual.layer2.3.bn3.running_var', 'visual.layer2.3.bn3.num_batches_tracked', 'visual.layer3.0.conv1.weight', 'visual.layer3.0.bn1.weight', 'visual.layer3.0.bn1.bias', 'visual.layer3.0.bn1.running_mean', 'visual.layer3.0.bn1.running_var', 'visual.layer3.0.bn1.num_batches_tracked', 'visual.layer3.0.conv2.weight', 'visual.layer3.0.bn2.weight', 'visual.layer3.0.bn2.bias', 'visual.layer3.0.bn2.running_mean', 'visual.layer3.0.bn2.running_var', 'visual.layer3.0.bn2.num_batches_tracked', 'visual.layer3.0.conv3.weight', 'visual.layer3.0.bn3.weight', 'visual.layer3.0.bn3.bias', 'visual.layer3.0.bn3.running_mean', 'visual.layer3.0.bn3.running_var', 'visual.layer3.0.bn3.num_batches_tracked', 'visual.layer3.0.downsample.0.weight', 'visual.layer3.0.downsample.1.weight', 'visual.layer3.0.downsample.1.bias', 'visual.layer3.0.downsample.1.running_mean', 'visual.layer3.0.downsample.1.running_var', 'visual.layer3.0.downsample.1.num_batches_tracked', 'visual.layer3.1.conv1.weight', 'visual.layer3.1.bn1.weight', 'visual.layer3.1.bn1.bias', 'visual.layer3.1.bn1.running_mean', 'visual.layer3.1.bn1.running_var', 'visual.layer3.1.bn1.num_batches_tracked', 'visual.layer3.1.conv2.weight', 'visual.layer3.1.bn2.weight', 'visual.layer3.1.bn2.bias', 'visual.layer3.1.bn2.running_mean', 'visual.layer3.1.bn2.running_var', 'visual.layer3.1.bn2.num_batches_tracked', 'visual.layer3.1.conv3.weight', 'visual.layer3.1.bn3.weight', 'visual.layer3.1.bn3.bias', 'visual.layer3.1.bn3.running_mean', 'visual.layer3.1.bn3.running_var', 'visual.layer3.1.bn3.num_batches_tracked', 'visual.layer3.2.conv1.weight', 'visual.layer3.2.bn1.weight', 'visual.layer3.2.bn1.bias', 'visual.layer3.2.bn1.running_mean', 'visual.layer3.2.bn1.running_var', 'visual.layer3.2.bn1.num_batches_tracked', 'visual.layer3.2.conv2.weight', 'visual.layer3.2.bn2.weight', 'visual.layer3.2.bn2.bias', 'visual.layer3.2.bn2.running_mean', 'visual.layer3.2.bn2.running_var', 'visual.layer3.2.bn2.num_batches_tracked', 'visual.layer3.2.conv3.weight', 'visual.layer3.2.bn3.weight', 'visual.layer3.2.bn3.bias', 'visual.layer3.2.bn3.running_mean', 'visual.layer3.2.bn3.running_var', 'visual.layer3.2.bn3.num_batches_tracked', 'visual.layer3.3.conv1.weight', 'visual.layer3.3.bn1.weight', 'visual.layer3.3.bn1.bias', 'visual.layer3.3.bn1.running_mean', 'visual.layer3.3.bn1.running_var', 'visual.layer3.3.bn1.num_batches_tracked', 'visual.layer3.3.conv2.weight', 'visual.layer3.3.bn2.weight', 'visual.layer3.3.bn2.bias', 'visual.layer3.3.bn2.running_mean', 'visual.layer3.3.bn2.running_var', 'visual.layer3.3.bn2.num_batches_tracked', 'visual.layer3.3.conv3.weight', 'visual.layer3.3.bn3.weight', 'visual.layer3.3.bn3.bias', 'visual.layer3.3.bn3.running_mean', 'visual.layer3.3.bn3.running_var', 'visual.layer3.3.bn3.num_batches_tracked', 'visual.layer3.4.conv1.weight', 'visual.layer3.4.bn1.weight', 'visual.layer3.4.bn1.bias', 'visual.layer3.4.bn1.running_mean', 'visual.layer3.4.bn1.running_var', 'visual.layer3.4.bn1.num_batches_tracked', 'visual.layer3.4.conv2.weight', 'visual.layer3.4.bn2.weight', 'visual.layer3.4.bn2.bias', 'visual.layer3.4.bn2.running_mean', 'visual.layer3.4.bn2.running_var', 'visual.layer3.4.bn2.num_batches_tracked', 'visual.layer3.4.conv3.weight', 'visual.layer3.4.bn3.weight', 'visual.layer3.4.bn3.bias', 'visual.layer3.4.bn3.running_mean', 'visual.layer3.4.bn3.running_var', 'visual.layer3.4.bn3.num_batches_tracked', 'visual.layer3.5.conv1.weight', 'visual.layer3.5.bn1.weight', 'visual.layer3.5.bn1.bias', 'visual.layer3.5.bn1.running_mean', 'visual.layer3.5.bn1.running_var', 'visual.layer3.5.bn1.num_batches_tracked', 'visual.layer3.5.conv2.weight', 'visual.layer3.5.bn2.weight', 'visual.layer3.5.bn2.bias', 'visual.layer3.5.bn2.running_mean', 'visual.layer3.5.bn2.running_var', 'visual.layer3.5.bn2.num_batches_tracked', 'visual.layer3.5.conv3.weight', 'visual.layer3.5.bn3.weight', 'visual.layer3.5.bn3.bias', 'visual.layer3.5.bn3.running_mean', 'visual.layer3.5.bn3.running_var', 'visual.layer3.5.bn3.num_batches_tracked', 'visual.layer4.0.conv1.weight', 'visual.layer4.0.bn1.weight', 'visual.layer4.0.bn1.bias', 'visual.layer4.0.bn1.running_mean', 'visual.layer4.0.bn1.running_var', 'visual.layer4.0.bn1.num_batches_tracked', 'visual.layer4.0.conv2.weight', 'visual.layer4.0.bn2.weight', 'visual.layer4.0.bn2.bias', 'visual.layer4.0.bn2.running_mean', 'visual.layer4.0.bn2.running_var', 'visual.layer4.0.bn2.num_batches_tracked', 'visual.layer4.0.conv3.weight', 'visual.layer4.0.bn3.weight', 'visual.layer4.0.bn3.bias', 'visual.layer4.0.bn3.running_mean', 'visual.layer4.0.bn3.running_var', 'visual.layer4.0.bn3.num_batches_tracked', 'visual.layer4.0.downsample.0.weight', 'visual.layer4.0.downsample.1.weight', 'visual.layer4.0.downsample.1.bias', 'visual.layer4.0.downsample.1.running_mean', 'visual.layer4.0.downsample.1.running_var', 'visual.layer4.0.downsample.1.num_batches_tracked', 'visual.layer4.1.conv1.weight', 'visual.layer4.1.bn1.weight', 'visual.layer4.1.bn1.bias', 'visual.layer4.1.bn1.running_mean', 'visual.layer4.1.bn1.running_var', 'visual.layer4.1.bn1.num_batches_tracked', 'visual.layer4.1.conv2.weight', 'visual.layer4.1.bn2.weight', 'visual.layer4.1.bn2.bias', 'visual.layer4.1.bn2.running_mean', 'visual.layer4.1.bn2.running_var', 'visual.layer4.1.bn2.num_batches_tracked', 'visual.layer4.1.conv3.weight', 'visual.layer4.1.bn3.weight', 'visual.layer4.1.bn3.bias', 'visual.layer4.1.bn3.running_mean', 'visual.layer4.1.bn3.running_var', 'visual.layer4.1.bn3.num_batches_tracked', 'visual.layer4.2.conv1.weight', 'visual.layer4.2.bn1.weight', 'visual.layer4.2.bn1.bias', 'visual.layer4.2.bn1.running_mean', 'visual.layer4.2.bn1.running_var', 'visual.layer4.2.bn1.num_batches_tracked', 'visual.layer4.2.conv2.weight', 'visual.layer4.2.bn2.weight', 'visual.layer4.2.bn2.bias', 'visual.layer4.2.bn2.running_mean', 'visual.layer4.2.bn2.running_var', 'visual.layer4.2.bn2.num_batches_tracked', 'visual.layer4.2.conv3.weight', 'visual.layer4.2.bn3.weight', 'visual.layer4.2.bn3.bias', 'visual.layer4.2.bn3.running_mean', 'visual.layer4.2.bn3.running_var', 'visual.layer4.2.bn3.num_batches_tracked', 'visual.attnpool.positional_embedding', 'visual.attnpool.k_proj.weight', 'visual.attnpool.k_proj.bias', 'visual.attnpool.q_proj.weight', 'visual.attnpool.q_proj.bias', 'visual.attnpool.v_proj.weight', 'visual.attnpool.v_proj.bias', 'visual.attnpool.c_proj.weight', 'visual.attnpool.c_proj.bias', 'transformer.resblocks.0.attn.in_proj_weight', 'transformer.resblocks.0.attn.in_proj_bias', 'transformer.resblocks.0.attn.out_proj.weight', 'transformer.resblocks.0.attn.out_proj.bias', 'transformer.resblocks.0.ln_1.weight', 'transformer.resblocks.0.ln_1.bias', 'transformer.resblocks.0.mlp.c_fc.weight', 'transformer.resblocks.0.mlp.c_fc.bias', 'transformer.resblocks.0.mlp.c_proj.weight', 'transformer.resblocks.0.mlp.c_proj.bias', 'transformer.resblocks.0.ln_2.weight', 'transformer.resblocks.0.ln_2.bias', 'transformer.resblocks.1.attn.in_proj_weight', 'transformer.resblocks.1.attn.in_proj_bias', 'transformer.resblocks.1.attn.out_proj.weight', 'transformer.resblocks.1.attn.out_proj.bias', 'transformer.resblocks.1.ln_1.weight', 'transformer.resblocks.1.ln_1.bias', 'transformer.resblocks.1.mlp.c_fc.weight', 'transformer.resblocks.1.mlp.c_fc.bias', 'transformer.resblocks.1.mlp.c_proj.weight', 'transformer.resblocks.1.mlp.c_proj.bias', 'transformer.resblocks.1.ln_2.weight', 'transformer.resblocks.1.ln_2.bias', 'transformer.resblocks.2.attn.in_proj_weight', 'transformer.resblocks.2.attn.in_proj_bias', 'transformer.resblocks.2.attn.out_proj.weight', 'transformer.resblocks.2.attn.out_proj.bias', 'transformer.resblocks.2.ln_1.weight', 'transformer.resblocks.2.ln_1.bias', 'transformer.resblocks.2.mlp.c_fc.weight', 'transformer.resblocks.2.mlp.c_fc.bias', 'transformer.resblocks.2.mlp.c_proj.weight', 'transformer.resblocks.2.mlp.c_proj.bias', 'transformer.resblocks.2.ln_2.weight', 'transformer.resblocks.2.ln_2.bias', 'transformer.resblocks.3.attn.in_proj_weight', 'transformer.resblocks.3.attn.in_proj_bias', 'transformer.resblocks.3.attn.out_proj.weight', 'transformer.resblocks.3.attn.out_proj.bias', 'transformer.resblocks.3.ln_1.weight', 'transformer.resblocks.3.ln_1.bias', 'transformer.resblocks.3.mlp.c_fc.weight', 'transformer.resblocks.3.mlp.c_fc.bias', 'transformer.resblocks.3.mlp.c_proj.weight', 'transformer.resblocks.3.mlp.c_proj.bias', 'transformer.resblocks.3.ln_2.weight', 'transformer.resblocks.3.ln_2.bias', 'transformer.resblocks.4.attn.in_proj_weight', 'transformer.resblocks.4.attn.in_proj_bias', 'transformer.resblocks.4.attn.out_proj.weight', 'transformer.resblocks.4.attn.out_proj.bias', 'transformer.resblocks.4.ln_1.weight', 'transformer.resblocks.4.ln_1.bias', 'transformer.resblocks.4.mlp.c_fc.weight', 'transformer.resblocks.4.mlp.c_fc.bias', 'transformer.resblocks.4.mlp.c_proj.weight', 'transformer.resblocks.4.mlp.c_proj.bias', 'transformer.resblocks.4.ln_2.weight', 'transformer.resblocks.4.ln_2.bias', 'transformer.resblocks.5.attn.in_proj_weight', 'transformer.resblocks.5.attn.in_proj_bias', 'transformer.resblocks.5.attn.out_proj.weight', 'transformer.resblocks.5.attn.out_proj.bias', 'transformer.resblocks.5.ln_1.weight', 'transformer.resblocks.5.ln_1.bias', 'transformer.resblocks.5.mlp.c_fc.weight', 'transformer.resblocks.5.mlp.c_fc.bias', 'transformer.resblocks.5.mlp.c_proj.weight', 'transformer.resblocks.5.mlp.c_proj.bias', 'transformer.resblocks.5.ln_2.weight', 'transformer.resblocks.5.ln_2.bias', 'transformer.resblocks.6.attn.in_proj_weight', 'transformer.resblocks.6.attn.in_proj_bias', 'transformer.resblocks.6.attn.out_proj.weight', 'transformer.resblocks.6.attn.out_proj.bias', 'transformer.resblocks.6.ln_1.weight', 'transformer.resblocks.6.ln_1.bias', 'transformer.resblocks.6.mlp.c_fc.weight', 'transformer.resblocks.6.mlp.c_fc.bias', 'transformer.resblocks.6.mlp.c_proj.weight', 'transformer.resblocks.6.mlp.c_proj.bias', 'transformer.resblocks.6.ln_2.weight', 'transformer.resblocks.6.ln_2.bias', 'transformer.resblocks.7.attn.in_proj_weight', 'transformer.resblocks.7.attn.in_proj_bias', 'transformer.resblocks.7.attn.out_proj.weight', 'transformer.resblocks.7.attn.out_proj.bias', 'transformer.resblocks.7.ln_1.weight', 'transformer.resblocks.7.ln_1.bias', 'transformer.resblocks.7.mlp.c_fc.weight', 'transformer.resblocks.7.mlp.c_fc.bias', 'transformer.resblocks.7.mlp.c_proj.weight', 'transformer.resblocks.7.mlp.c_proj.bias', 'transformer.resblocks.7.ln_2.weight', 'transformer.resblocks.7.ln_2.bias', 'transformer.resblocks.8.attn.in_proj_weight', 'transformer.resblocks.8.attn.in_proj_bias', 'transformer.resblocks.8.attn.out_proj.weight', 'transformer.resblocks.8.attn.out_proj.bias', 'transformer.resblocks.8.ln_1.weight', 'transformer.resblocks.8.ln_1.bias', 'transformer.resblocks.8.mlp.c_fc.weight', 'transformer.resblocks.8.mlp.c_fc.bias', 'transformer.resblocks.8.mlp.c_proj.weight', 'transformer.resblocks.8.mlp.c_proj.bias', 'transformer.resblocks.8.ln_2.weight', 'transformer.resblocks.8.ln_2.bias', 'transformer.resblocks.9.attn.in_proj_weight', 'transformer.resblocks.9.attn.in_proj_bias', 'transformer.resblocks.9.attn.out_proj.weight', 'transformer.resblocks.9.attn.out_proj.bias', 'transformer.resblocks.9.ln_1.weight', 'transformer.resblocks.9.ln_1.bias', 'transformer.resblocks.9.mlp.c_fc.weight', 'transformer.resblocks.9.mlp.c_fc.bias', 'transformer.resblocks.9.mlp.c_proj.weight', 'transformer.resblocks.9.mlp.c_proj.bias', 'transformer.resblocks.9.ln_2.weight', 'transformer.resblocks.9.ln_2.bias', 'transformer.resblocks.10.attn.in_proj_weight', 'transformer.resblocks.10.attn.in_proj_bias', 'transformer.resblocks.10.attn.out_proj.weight', 'transformer.resblocks.10.attn.out_proj.bias', 'transformer.resblocks.10.ln_1.weight', 'transformer.resblocks.10.ln_1.bias', 'transformer.resblocks.10.mlp.c_fc.weight', 'transformer.resblocks.10.mlp.c_fc.bias', 'transformer.resblocks.10.mlp.c_proj.weight', 'transformer.resblocks.10.mlp.c_proj.bias', 'transformer.resblocks.10.ln_2.weight', 'transformer.resblocks.10.ln_2.bias', 'transformer.resblocks.11.attn.in_proj_weight', 'transformer.resblocks.11.attn.in_proj_bias', 'transformer.resblocks.11.attn.out_proj.weight', 'transformer.resblocks.11.attn.out_proj.bias', 'transformer.resblocks.11.ln_1.weight', 'transformer.resblocks.11.ln_1.bias', 'transformer.resblocks.11.mlp.c_fc.weight', 'transformer.resblocks.11.mlp.c_fc.bias', 'transformer.resblocks.11.mlp.c_proj.weight', 'transformer.resblocks.11.mlp.c_proj.bias', 'transformer.resblocks.11.ln_2.weight', 'transformer.resblocks.11.ln_2.bias', 'token_embedding.weight', 'ln_final.weight', 'ln_final.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(model.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resized bias from size:1 * 1024 to size: 2048 * 1024\n",
      "torch.Size([2048, 1024])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "def resize_attn_pooling_pos_embed(posemb, length):\n",
    "    old_N, old_C = posemb.shape\n",
    "    print(f'Resized position embedding from size:{old_N} * {old_C} to size: {length} * {old_C}')\n",
    "    posemb = posemb.reshape(1, 1, old_N, old_C).permute(0,3,1,2)  # [1, 1, 50, 2048]\n",
    "    posemb = F.interpolate(posemb, size=(1,length), mode='bilinear')\n",
    "    posemb = posemb.permute(0,2,3,1)\n",
    "    return posemb.squeeze()\n",
    "\n",
    "def resize_bias(bias, length):\n",
    "    old_N, old_C = bias.shape\n",
    "    print(f'Resized bias from size:{old_N} * {old_C} to size: {length} * {old_C}')\n",
    "    bias = bias.reshape(1, 1, old_N, old_C).permute(0,3,1,2)  # [1, 1, 50, 2048]\n",
    "    bias = F.interpolate(bias, size=(1,length), mode='bilinear')\n",
    "    bias = bias.permute(0,2,3,1)\n",
    "    return bias.squeeze()\n",
    "\n",
    "v = torch.rand(1,1024)\n",
    "result = resize_bias(v, 2048)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "m = nn.Linear(20, 30)\n",
    "input = torch.randn(128,2,3,20)\n",
    "output = m(input)\n",
    "print(output.size()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 14.601387023925781\n",
      "Epoch: 1, Loss: 14.249747276306152\n",
      "Epoch: 2, Loss: 13.901070594787598\n",
      "Epoch: 3, Loss: 13.554640769958496\n",
      "Epoch: 4, Loss: 13.209765434265137\n",
      "Saving checkpoint at epoch 4\n",
      "Epoch: 5, Loss: 12.86635971069336\n",
      "Epoch: 6, Loss: 12.524091720581055\n",
      "Epoch: 7, Loss: 12.182626724243164\n",
      "Epoch: 8, Loss: 11.841975212097168\n",
      "Epoch: 9, Loss: 11.50204086303711\n",
      "Saving checkpoint at epoch 9\n",
      "Resuming training from epoch 5\n",
      "Epoch: 5, Loss: 12.86635971069336\n",
      "Epoch: 6, Loss: 12.524091720581055\n",
      "Epoch: 7, Loss: 12.182626724243164\n",
      "Epoch: 8, Loss: 11.841975212097168\n",
      "Epoch: 9, Loss: 11.50204086303711\n",
      "Saving checkpoint at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huzhangyi/anaconda3/envs/Tri_Modality/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "/home/huzhangyi/anaconda3/envs/Tri_Modality/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "torch.manual_seed(0)\n",
    "# 定义一个简单的模型\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 20)\n",
    "        self.fc2 = nn.Linear(20, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 生成一些简单的数据\n",
    "x = torch.rand(100, 1)\n",
    "y = x * 2 + 3\n",
    "\n",
    "# 初始化模型\n",
    "model = SimpleModel()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 定义个性化的参数组\n",
    "optimizer = optim.SGD([\n",
    "    {'params': model.fc1.parameters(), 'lr': 0.01, 'weight_decay': 5e-4},\n",
    "    {'params': model.fc2.parameters(), 'lr': 0.001, 'weight_decay': 5e-5}\n",
    "])\n",
    "\n",
    "# 定义学习率调度器\n",
    "scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "def train(cur_epoch, total_epoch=10, checkpoint_path=None):\n",
    "    model.train()\n",
    "    for ep in range(cur_epoch,total_epoch):\n",
    "        scheduler.step(cur_epoch)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'Epoch: {ep}, Loss: {loss.item()}')\n",
    "        if (ep + 1) % 5 == 0:\n",
    "            # 每5个epoch保存一次checkpoint\n",
    "            print(f'Saving checkpoint at epoch {ep}')\n",
    "            torch.save({\n",
    "                'epoch': ep,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'loss': loss,\n",
    "            }, str(ep) + checkpoint_path)\n",
    "\n",
    "# 模拟中断并保存checkpoint\n",
    "checkpoint_path = 'model_checkpoint.pth'\n",
    "train(0,10, checkpoint_path)  # 假设在第5个epoch时中断\n",
    "\n",
    "# 加载checkpoint并从中断处继续训练\n",
    "def resume_training(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "\n",
    "    print(f\"Resuming training from epoch {start_epoch}\")\n",
    "    train(10 - start_epoch,10,checkpoint_path)  # 继续训练剩余的epoch\n",
    "\n",
    "resume_training('4'+checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [59904/60000 (100%)]\tLoss: 0.381618\n",
      "Checkpoint saved to checkpoint.pth.tar\n",
      "Train Epoch: 1 [59904/60000 (100%)]\tLoss: 0.333526\n",
      "Checkpoint loaded from checkpoint.pth.tar, epoch 0\n",
      "Train Epoch: 1 [59904/60000 (100%)]\tLoss: 0.333705\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 简单的多层感知器模型\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(784, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.layers(x)\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch, scaler):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast():  # 开启自动混合精度训练\n",
    "            output = model(data)\n",
    "            loss = nn.CrossEntropyLoss()(output, target)\n",
    "        \n",
    "        scaler.scale(loss).backward()  # 缩放梯度\n",
    "        scaler.step(optimizer)  # 优化器步进\n",
    "        scaler.update()  # 更新scaler的缩放因子\n",
    "\n",
    "        if (batch_idx+1) == len(train_loader):\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "\n",
    "def save_checkpoint(model, optimizer, scaler, epoch, filename='checkpoint.pth.tar'):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scaler_state_dict': scaler.state_dict(),\n",
    "    }, filename)\n",
    "    print(f'Checkpoint saved to {filename}')\n",
    "\n",
    "def load_checkpoint(model, optimizer, scaler, filename='checkpoint.pth.tar'):\n",
    "    checkpoint = torch.load(filename)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    # scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    print(f'Checkpoint loaded from {filename}, epoch {epoch}')\n",
    "    return epoch\n",
    "\n",
    "def main():\n",
    "    torch.manual_seed(0)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False,drop_last=True)\n",
    "\n",
    "    model = SimpleMLP().to(device)\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    start_epoch = 0\n",
    "    epochs = 1  # 为了演示，我们只训练1个epoch\n",
    "\n",
    "    # 模拟训练中断，保存checkpoint\n",
    "    train(model, device, train_loader, optimizer, start_epoch, scaler)\n",
    "    save_checkpoint(model, optimizer, scaler, start_epoch)\n",
    "    train(model, device, train_loader, optimizer, start_epoch+1, scaler)\n",
    "\n",
    "    # 假设我们现在是从checkpoint恢复\n",
    "    loaded_epoch = load_checkpoint(model, optimizer, scaler)\n",
    "    for epoch in range(loaded_epoch + 1, loaded_epoch + 1 + epochs):\n",
    "        train(model, device, train_loader, optimizer, epoch, scaler)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huzhangyi/anaconda3/envs/Tri_Modality/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "/home/huzhangyi/anaconda3/envs/Tri_Modality/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [59904/60000 (100%)]\tLoss: 0.381618\n",
      "Checkpoint saved to checkpoint.pth.tar\n",
      "Train Epoch: 1 [59904/60000 (100%)]\tLoss: 0.341324\n",
      "Checkpoint loaded from checkpoint.pth.tar, epoch 0\n",
      "Train Epoch: 1 [59904/60000 (100%)]\tLoss: 0.341324\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(784, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.layers(x)\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch, scaler, scheduler=None):\n",
    "    model.train()\n",
    "    if scheduler:\n",
    "        scheduler.step(epoch)  # 更新学习率\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast():  # 开启自动混合精度训练\n",
    "            output = model(data)\n",
    "            loss = nn.CrossEntropyLoss()(output, target)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        if (batch_idx+1) == len(train_loader):\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "    \n",
    "    \n",
    "\n",
    "def save_checkpoint(model, optimizer, scaler, scheduler, epoch, filename='checkpoint.pth.tar'):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scaler_state_dict': scaler.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),  # 保存scheduler状态\n",
    "    }, filename)\n",
    "    print(f'Checkpoint saved to {filename}')\n",
    "\n",
    "def load_checkpoint(model, optimizer, scaler, scheduler, filename='checkpoint.pth.tar'):\n",
    "    checkpoint = torch.load(filename)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scaler.load_state_dict(checkpoint['scaler_state_dict'])  # 注意: 这行被注释掉了，因为您的原始代码中也是注释的\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])  # 加载scheduler状态\n",
    "    epoch = checkpoint['epoch']\n",
    "    print(f'Checkpoint loaded from {filename}, epoch {epoch}')\n",
    "    return epoch\n",
    "\n",
    "def main():\n",
    "    torch.manual_seed(0)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False, drop_last=True)\n",
    "\n",
    "    model = SimpleMLP().to(device)\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    scaler = GradScaler()\n",
    "    scheduler = StepLR(optimizer, step_size=1, gamma=0.7)  # 定义scheduler\n",
    "\n",
    "    start_epoch = 0\n",
    "    epochs = 1  # 为了演示，我们只训练1个epoch\n",
    "\n",
    "    # 模拟训练中断，保存checkpoint\n",
    "    train(model, device, train_loader, optimizer, start_epoch, scaler, scheduler)\n",
    "    save_checkpoint(model, optimizer, scaler, scheduler, start_epoch)\n",
    "    train(model, device, train_loader, optimizer, start_epoch+1, scaler, scheduler)\n",
    "\n",
    "\n",
    "    # 假设我们现在是从checkpoint恢复\n",
    "    loaded_epoch = load_checkpoint(model, optimizer, scaler, scheduler)\n",
    "    for epoch in range(loaded_epoch + 1, loaded_epoch + 1 + epochs):\n",
    "        train(model, device, train_loader, optimizer, epoch, scaler, scheduler)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# 创建模拟数据和模型\n",
    "x = torch.randn(10, 3)\n",
    "y = torch.randn(10, 2)\n",
    "\n",
    "model = torch.nn.Linear(3, 2)\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 损失函数\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# 前向传播以计算两个损失\n",
    "y_pred = model(x)\n",
    "loss1 = criterion(y_pred, y)\n",
    "loss2 = criterion(y_pred, y * 0.5)\n",
    "\n",
    "# 方式1: 合并损失后进行反向传播\n",
    "optimizer.zero_grad()  # 清空梯度\n",
    "(loss1 + loss2).backward()\n",
    "optimizer.step()\n",
    "\n",
    "# 保存方式1的参数和梯度\n",
    "params_with_combined_loss = [(param.clone(), param.grad.clone()) for param in model.parameters()]\n",
    "\n",
    "# # 重置模型参数\n",
    "# with torch.no_grad():\n",
    "#     for param, (original_param, _) in zip(model.parameters(), params_with_combined_loss):\n",
    "#         param.copy_(original_param)\n",
    "\n",
    "# # 方式2: 分别对两个损失进行反向传播\n",
    "# optimizer.zero_grad()  # 清空梯度\n",
    "# loss1.backward(retain_graph=True)  # 对loss1进行反向传播，保留计算图\n",
    "# loss2.backward()  # 对loss2进行反向传播\n",
    "# optimizer.step()\n",
    "\n",
    "# # 验证两种方法是否等效\n",
    "# params_with_separate_loss = [param for param in model.parameters()]\n",
    "\n",
    "# for (combined_param, combined_grad), separate_param in zip(params_with_combined_loss, params_with_separate_loss):\n",
    "#     assert torch.allclose(combined_param, separate_param), \"Parameters are not equal.\"\n",
    "#     assert torch.allclose(combined_grad, separate_param.grad), \"Gradients are not equal.\"\n",
    "\n",
    "# print(\"两种方法等效！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "两种方法等效！\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# 创建模拟数据和模型\n",
    "x = torch.randn(10, 3)\n",
    "y = torch.randn(10, 2)\n",
    "\n",
    "model = torch.nn.Linear(3, 2)\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 损失函数\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# 前向传播以计算两个损失\n",
    "y_pred = model(x)\n",
    "loss1 = criterion(y_pred, y)\n",
    "loss2 = criterion(y_pred, y * 0.5)\n",
    "\n",
    "# 方式2: 分别对两个损失进行反向传播\n",
    "optimizer.zero_grad()  # 清空梯度\n",
    "loss1.backward(retain_graph=True)  # 对loss1进行反向传播，保留计算图\n",
    "loss2.backward()  # 对loss2进行反向传播\n",
    "optimizer.step()\n",
    "\n",
    "# 验证两种方法是否等效\n",
    "params_with_separate_loss = [param for param in model.parameters()]\n",
    "\n",
    "for (combined_param, combined_grad), separate_param in zip(params_with_combined_loss, params_with_separate_loss):\n",
    "    assert torch.allclose(combined_param, separate_param), \"Parameters are not equal.\"\n",
    "    assert torch.allclose(combined_grad, separate_param.grad), \"Gradients are not equal.\"\n",
    "\n",
    "print(\"两种方法等效！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "loss_names = '12,2,3'\n",
    "loss_names = loss_names.split(',')\n",
    "loss_names\n",
    "\n",
    "print('1' in loss_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kl_loss = F.kl_div(aligned_matrix, true_matrix, reduction='batchmean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# from tools.utils import os_walk\n",
    "import torch\n",
    "def os_walk(folder_dir):\n",
    "    for root, dirs, files in os.walk(folder_dir):\n",
    "        files = sorted(files, reverse=True)\n",
    "        dirs = sorted(dirs, reverse=True)\n",
    "        return root, dirs, files\n",
    "model = torch.nn.Linear(3, 2)\n",
    "save_model_path = \"/home/huzhangyi/projects/WORK_2024/CMBR-B/network/clip_model/save_model_path\"\n",
    "max_save_model_num = 1\n",
    "\n",
    "def save_model(save_epoch, is_best, mode='Fusion'): # mode = ['IR', 'Fusion', 'Text'] or their composition\n",
    "        if is_best:\n",
    "            model_file_path = os.path.join(save_model_path, f'model_{mode}_{save_epoch}.pth')\n",
    "            torch.save(model.state_dict(), model_file_path)\n",
    "\n",
    "        if max_save_model_num > 0:\n",
    "            root, _, files = os_walk(save_model_path)\n",
    "            if mode == 'Fusion' or mode == 'IR' or mode == 'Text':\n",
    "                for file in files:\n",
    "                    if '.pth' not in file:\n",
    "                        files.remove(file)\n",
    "                    if mode not in file:\n",
    "                        files.remove(file)\n",
    "                if len(files) > max_save_model_num:\n",
    "                    file_iters = sorted([int(file.replace('.pth', '').split('_')[-1]) for file in files], reverse=False)\n",
    "                    model_file_path = os.path.join(root, f'model_{mode}_{file_iters[0]}.pth')\n",
    "                    os.remove(model_file_path)\n",
    "            else:\n",
    "                raise ValueError(\"savinf mode must be in ['Fusion', 'IR', 'Text']\")\n",
    "\n",
    "save_model(1, True, 'Fusion')\n",
    "save_model(2, True, 'Fusion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "targets1 = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]).unsqueeze(1)\n",
    "targets2 = torch.tensor([1, 2, 3, 4, 5]).unsqueeze(1)\n",
    "N = targets1.size(0)\n",
    "M = targets2.size(0)\n",
    "is_pos = targets1.expand(N, M).eq(targets2.expand(M, N).t()).float()\n",
    "is_neg = targets1.expand(N, M).ne(targets2.expand(M, N).t()).float()\n",
    "print(is_pos)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 5])\n",
      "torch.Size([10, 5])\n"
     ]
    }
   ],
   "source": [
    "print(is_pos.shape)\n",
    "print(is_neg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "model = nn.Linear(3, 2)\n",
    "model.eval()\n",
    "# model.requires_grad_()\n",
    "# 查看模型是否传递梯度\n",
    "print(model.weight.requires_grad)\n",
    "model.requires_grad_(False)\n",
    "print(model.weight.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
